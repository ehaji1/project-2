{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Stock Predictor Using Closing Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this section, we will prepare the training and testing data for the LSTM model.\n",
    "\n",
    "We will need to:\n",
    "1. Use the `window_data` function to generate the X and y values for the model.\n",
    "2. Split the data into 70% training and 30% testing\n",
    "3. Apply the MinMaxScaler to the `X` and `y` values\n",
    "4. Reshape the `X_train` and `X_test` data for the model.\n",
    "\n",
    "**Note:** The required input format for the LSTM is:\n",
    "\n",
    "```python\n",
    "reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_beef = Path(\"Beef84_22.csv\")\n",
    "file_eggs = Path(\"Eggs80_22.csv\")\n",
    "file_bread = Path(\"Bread80_22.csv\")\n",
    "file_chicken = Path(\"Chicken80_22.csv\")\n",
    "file_diesel = Path(\"Diesel98_22s.csv\")\n",
    "file_electric = Path(\"Electricity79_22.csv\")\n",
    "file_energy = Path(\"Energy00_22.csv\")\n",
    "file_flour = Path(\"Flour80_22.csv\")\n",
    "file_fuel = Path(\"Fuel79_22.csv\")\n",
    "file_gas = Path(\"Gasoline80_22.csv\")\n",
    "file_malt = Path(\"Malt96_22.csv\")\n",
    "file_medical = Path(\"Medical00_22.csv\")\n",
    "file_milk = Path(\"Milk95_22.csv\")\n",
    "file_pres = Path(\"Prescription80_22.csv\")\n",
    "file_shelter = Path(\"Shelter80_22.csv\")\n",
    "file_sugar = Path(\"Sugar80_22.csv\")\n",
    "file_utility = Path(\"Utility00_22.csv\")\n",
    "\n",
    "file_cpi = Path(\"CPI_Average.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "beef_file = pd.read_csv(file_beef)\n",
    "eggs_file = pd.read_csv(file_eggs)\n",
    "bread_file = pd.read_csv(file_bread)\n",
    "chicken_file = pd.read_csv(file_chicken)\n",
    "diesel_file = pd.read_csv(file_diesel)\n",
    "electricity_file = pd.read_csv(file_electric)\n",
    "energy_file = pd.read_csv(file_energy)\n",
    "flour_file = pd.read_csv(file_flour)\n",
    "fuel_file = pd.read_csv(file_fuel)\n",
    "gasoline_file = pd.read_csv(file_gas)\n",
    "malt_file = pd.read_csv(file_malt)\n",
    "medical_file = pd.read_csv(file_medical)\n",
    "milk_file = pd.read_csv(file_milk)\n",
    "presecription_file = pd.read_csv(file_pres)\n",
    "shelter_file = pd.read_csv(file_shelter)\n",
    "sugar_file = pd.read_csv(file_sugar)\n",
    "utility_file = pd.read_csv(file_utility)\n",
    "\n",
    "CPI_file = pd.read_csv(file_cpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Eggs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-1980</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02-01-1980</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-01-1980</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04-01-1980</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-01-1980</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year   Eggs\n",
       "0  01-01-1980  0.879\n",
       "1  02-01-1980  0.774\n",
       "2  03-01-1980  0.812\n",
       "3  04-01-1980  0.797\n",
       "4  05-01-1980  0.737"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beef_file.head()\n",
    "eggs_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beef = pd.DataFrame(beef_file)\n",
    "df_beef.set_index(pd.to_datetime(df_beef['Year'], infer_datetime_format=True), inplace=True)\n",
    "df_beef = df_beef.drop(columns=['Year'], axis=1)\n",
    "df_beef = df_beef.pct_change()\n",
    "\n",
    "df_eggs = pd.DataFrame(eggs_file)\n",
    "df_eggs.set_index(pd.to_datetime(df_eggs['Year'], infer_datetime_format=True), inplace=True)\n",
    "df_eggs = df_eggs.drop(columns=['Year'], axis=1)\n",
    "df_eggs = df_eggs.pct_change()\n",
    "\n",
    "df_bread = pd.DataFrame(bread_file)\n",
    "df_bread.set_index(pd.to_datetime(df_bread['Year'], infer_datetime_format=True), inplace=True) \n",
    "df_bread = df_bread.drop(columns=['Year'], axis=1)\n",
    "df_bread = df_bread.pct_change()\n",
    "\n",
    "df_chicken = pd.DataFrame(chicken_file)\n",
    "df_chicken.set_index(pd.to_datetime(df_chicken['Year'], infer_datetime_format=True), inplace=True)\n",
    "df_chicken = df_chicken.drop(columns=['Year'], axis=1)\n",
    "df_chicken  = df_chicken .pct_change()\n",
    "\n",
    "df_diesel = pd.DataFrame(diesel_file)\n",
    "df_diesel.set_index(pd.to_datetime(df_diesel ['Year'], infer_datetime_format=True), inplace=True)\n",
    "df_diesel  = df_diesel .drop(columns=['Year'], axis=1)\n",
    "df_diesel = df_diesel.pct_change()\n",
    "\n",
    "df_electric = pd.DataFrame(electricity_file)\n",
    "df_electric.set_index(pd.to_datetime(df_electric['Year'], infer_datetime_format=True), inplace=True)\n",
    "df_electric = df_electric.drop(columns=['Year'], axis=1)\n",
    "df_electric = df_electric.pct_change()\n",
    "\n",
    "df_energy = pd.DataFrame(energy_file)\n",
    "df_energy.set_index(pd.to_datetime(df_energy['Year'], infer_datetime_format=True), inplace=True)\n",
    "df_energy = df_energy.drop(columns=['Year'], axis=1)\n",
    "df_energy = df_energy.pct_change()\n",
    "\n",
    "\n",
    "df_flour = pd.DataFrame(flour_file)\n",
    "df_flour.set_index(pd.to_datetime(df_flour['Year'], infer_datetime_format=True), inplace=True)\n",
    "df_flour = df_flour.drop(columns=['Year'], axis=1)\n",
    "df_flour = df_flour.pct_change()\n",
    "\n",
    "\n",
    "df_fuel = pd.DataFrame(fuel_file)\n",
    "df_fuel.set_index(pd.to_datetime(df_fuel['Year'], infer_datetime_format=True), inplace=True)\n",
    "df_fuel = df_fuel.drop(columns=['Year'], axis=1)\n",
    "df_fuel = df_fuel.pct_change()\n",
    "\n",
    "df_gas = pd.DataFrame(gasoline_file)\n",
    "df_gas.set_index(pd.to_datetime(df_gas['Year'], infer_datetime_format=True), inplace=True)\n",
    "df_gas = df_gas.drop(columns=['Year'], axis=1)\n",
    "df_gas = df_gas.pct_change()\n",
    "\n",
    "\n",
    "df_malt = pd.DataFrame(malt_file)\n",
    "df_malt.set_index(pd.to_datetime(df_malt['Year'], infer_datetime_format=True), inplace=True)\n",
    "df_malt = df_malt.drop(columns=['Year'], axis=1)\n",
    "df_malt = df_malt.pct_change()\n",
    "\n",
    "\n",
    "df_medical = pd.DataFrame(medical_file)\n",
    "df_medical.set_index(pd.to_datetime(df_medical['Year'], infer_datetime_format=True), inplace=True)\n",
    "df_medical = df_medical.drop(columns=['Year'], axis=1)\n",
    "df_medical = df_medical.pct_change()\n",
    "\n",
    "\n",
    "df_milk = pd.DataFrame(milk_file)\n",
    "df_milk.set_index(pd.to_datetime(df_milk['Year'], infer_datetime_format=True), inplace=True)\n",
    "df_milk = df_milk.drop(columns=['Year'], axis=1)\n",
    "df_milk = df_milk.pct_change()\n",
    "\n",
    "\n",
    "\n",
    "df_pres = pd.DataFrame(presecription_file)\n",
    "df_pres.set_index(pd.to_datetime(df_pres['Year'], infer_datetime_format=True), inplace=True)\n",
    "df_pres = df_pres.drop(columns=['Year'], axis=1)\n",
    "df_pres = df_pres.pct_change()\n",
    "\n",
    "\n",
    "df_shelter = pd.DataFrame(shelter_file)\n",
    "df_shelter.set_index(pd.to_datetime(df_shelter ['Year'], infer_datetime_format=True), inplace=True)\n",
    "df_shelter  = df_shelter.drop(columns=['Year'], axis=1)\n",
    "df_shelter = df_shelter.pct_change()\n",
    "\n",
    "df_sugar = pd.DataFrame(sugar_file)\n",
    "df_sugar.set_index(pd.to_datetime(df_sugar['Year'], infer_datetime_format=True), inplace=True)\n",
    "df_sugar = df_sugar.drop(columns=['Year'], axis=1)\n",
    "df_sugar = df_sugar.pct_change()\n",
    "\n",
    "df_utility = pd.DataFrame(utility_file)\n",
    "df_utility.set_index(pd.to_datetime(df_utility['Year'], infer_datetime_format=True), inplace=True) \n",
    "df_utility = df_utility.drop(columns=['Year'], axis=1)\n",
    "df_utility  = df_utility .pct_change()\n",
    "\n",
    "df_cpi = pd.DataFrame(CPI_file)\n",
    "df_cpi.set_index(pd.to_datetime(df_cpi['Year'], infer_datetime_format=True), inplace=True) \n",
    "df_cpi = df_cpi.drop(columns=['Year'], axis=1)\n",
    "df_cpi  = df_cpi.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-02-01</th>\n",
       "      <td>0.038760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-03-01</th>\n",
       "      <td>-0.023881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-04-01</th>\n",
       "      <td>0.017584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-05-01</th>\n",
       "      <td>-0.022539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Beef\n",
       "Year                \n",
       "1980-01-01       NaN\n",
       "1984-02-01  0.038760\n",
       "1984-03-01 -0.023881\n",
       "1984-04-01  0.017584\n",
       "1984-05-01 -0.022539"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_beef.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beef</th>\n",
       "      <th>Chicken</th>\n",
       "      <th>Eggs</th>\n",
       "      <th>Bread</th>\n",
       "      <th>Diesel</th>\n",
       "      <th>Electric79_22</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Flour</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Gasoline</th>\n",
       "      <th>Malt</th>\n",
       "      <th>Medical</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Utility</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>Shelter</th>\n",
       "      <th>CPI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>-0.029450</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>0.059783</td>\n",
       "      <td>0.008899</td>\n",
       "      <td>0.025792</td>\n",
       "      <td>-0.011765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.071161</td>\n",
       "      <td>0.092831</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>0.058419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.031304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025822</td>\n",
       "      <td>0.007953</td>\n",
       "      <td>0.002971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-01</th>\n",
       "      <td>0.022252</td>\n",
       "      <td>-0.012276</td>\n",
       "      <td>-0.013333</td>\n",
       "      <td>0.018743</td>\n",
       "      <td>0.123563</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.034930</td>\n",
       "      <td>-0.066434</td>\n",
       "      <td>0.357443</td>\n",
       "      <td>0.048257</td>\n",
       "      <td>-0.046537</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>-0.002873</td>\n",
       "      <td>0.020937</td>\n",
       "      <td>-0.011442</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>0.005924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-01</th>\n",
       "      <td>0.010554</td>\n",
       "      <td>0.017208</td>\n",
       "      <td>-0.032225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050145</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>-0.157993</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.069240</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>-0.010443</td>\n",
       "      <td>-0.005859</td>\n",
       "      <td>-0.006944</td>\n",
       "      <td>0.006283</td>\n",
       "      <td>0.008245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-01</th>\n",
       "      <td>0.033943</td>\n",
       "      <td>0.004699</td>\n",
       "      <td>0.008593</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>-0.038437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.010101</td>\n",
       "      <td>-0.007018</td>\n",
       "      <td>-0.053716</td>\n",
       "      <td>-0.022918</td>\n",
       "      <td>-0.057325</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.009098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.034965</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-01</th>\n",
       "      <td>-0.008838</td>\n",
       "      <td>-0.015903</td>\n",
       "      <td>-0.092652</td>\n",
       "      <td>-0.012945</td>\n",
       "      <td>-0.009174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.067138</td>\n",
       "      <td>-0.017885</td>\n",
       "      <td>-0.002346</td>\n",
       "      <td>0.052928</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.008841</td>\n",
       "      <td>0.024155</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.001168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01</th>\n",
       "      <td>-0.024028</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>0.127282</td>\n",
       "      <td>0.036437</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006429</td>\n",
       "      <td>0.025773</td>\n",
       "      <td>0.024613</td>\n",
       "      <td>-0.015915</td>\n",
       "      <td>-0.039439</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>-0.008709</td>\n",
       "      <td>0.004128</td>\n",
       "      <td>-0.013725</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>-0.000671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-01</th>\n",
       "      <td>0.042077</td>\n",
       "      <td>-0.002573</td>\n",
       "      <td>0.036208</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>-0.002921</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.009080</td>\n",
       "      <td>0.057789</td>\n",
       "      <td>0.027718</td>\n",
       "      <td>0.009923</td>\n",
       "      <td>0.055657</td>\n",
       "      <td>0.007051</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.008501</td>\n",
       "      <td>0.031809</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>0.004971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-01</th>\n",
       "      <td>0.022766</td>\n",
       "      <td>-0.003439</td>\n",
       "      <td>-0.003218</td>\n",
       "      <td>0.031226</td>\n",
       "      <td>0.010841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.080760</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>-0.005757</td>\n",
       "      <td>-0.032844</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>-0.000517</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>-0.011561</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.002904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-01</th>\n",
       "      <td>-0.036959</td>\n",
       "      <td>0.007765</td>\n",
       "      <td>0.016144</td>\n",
       "      <td>0.021953</td>\n",
       "      <td>0.135652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050315</td>\n",
       "      <td>0.074725</td>\n",
       "      <td>0.108149</td>\n",
       "      <td>0.072338</td>\n",
       "      <td>0.044683</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>-0.022745</td>\n",
       "      <td>0.017878</td>\n",
       "      <td>-0.017544</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>0.008668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-01</th>\n",
       "      <td>0.013083</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>-0.060826</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>0.054364</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.042787</td>\n",
       "      <td>0.059305</td>\n",
       "      <td>0.047580</td>\n",
       "      <td>0.055744</td>\n",
       "      <td>-0.038494</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>0.020332</td>\n",
       "      <td>0.025794</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.006065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Beef   Chicken      Eggs     Bread    Diesel  Electric79_22  \\\n",
       "Year                                                                          \n",
       "2000-01-01 -0.029450  0.005698  0.059783  0.008899  0.025792      -0.011765   \n",
       "2000-02-01  0.022252 -0.012276 -0.013333  0.018743  0.123563       0.011905   \n",
       "2000-03-01  0.010554  0.017208 -0.032225  0.000000  0.014706       0.000000   \n",
       "2000-04-01  0.033943  0.004699  0.008593  0.003247 -0.038437       0.000000   \n",
       "2000-05-01 -0.008838 -0.015903 -0.092652 -0.012945 -0.009174       0.000000   \n",
       "...              ...       ...       ...       ...       ...            ...   \n",
       "2007-12-01 -0.024028  0.004307  0.127282  0.036437  0.000292       0.000000   \n",
       "2008-01-01  0.042077 -0.002573  0.036208  0.000781 -0.002921       0.008696   \n",
       "2008-02-01  0.022766 -0.003439 -0.003218  0.031226  0.010841       0.000000   \n",
       "2008-03-01 -0.036959  0.007765  0.016144  0.021953  0.135652       0.000000   \n",
       "2008-04-01  0.013083  0.006849 -0.060826  0.017037  0.054364       0.017241   \n",
       "\n",
       "              Energy     Flour      Fuel  Gasoline      Malt   Medical  \\\n",
       "Year                                                                     \n",
       "2000-01-01       NaN  0.071161  0.092831  0.003587  0.058419       NaN   \n",
       "2000-02-01  0.034930 -0.066434  0.357443  0.048257 -0.046537  0.005970   \n",
       "2000-03-01  0.050145  0.067416 -0.157993  0.115942  0.069240  0.003956   \n",
       "2000-04-01 -0.010101 -0.007018 -0.053716 -0.022918 -0.057325  0.001970   \n",
       "2000-05-01  0.001855  0.067138 -0.017885 -0.002346  0.052928  0.002950   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2007-12-01 -0.006429  0.025773  0.024613 -0.015915 -0.039439  0.002534   \n",
       "2008-01-01  0.009080  0.057789  0.027718  0.009923  0.055657  0.007051   \n",
       "2008-02-01  0.000512  0.080760  0.000300 -0.005757 -0.032844  0.005105   \n",
       "2008-03-01  0.050315  0.074725  0.108149  0.072338  0.044683  0.000830   \n",
       "2008-04-01  0.042787  0.059305  0.047580  0.055744 -0.038494  0.000851   \n",
       "\n",
       "                Milk   Utility     Sugar   Shelter       CPI  \n",
       "Year                                                          \n",
       "2000-01-01 -0.031304       NaN  0.025822  0.007953  0.002971  \n",
       "2000-02-01 -0.002873  0.020937 -0.011442  0.004734  0.005924  \n",
       "2000-03-01 -0.010443 -0.005859 -0.006944  0.006283  0.008245  \n",
       "2000-04-01  0.009098  0.000000 -0.034965  0.000520  0.000584  \n",
       "2000-05-01  0.003246  0.008841  0.024155  0.000520  0.001168  \n",
       "...              ...       ...       ...       ...       ...  \n",
       "2007-12-01 -0.008709  0.004128 -0.013725  0.000681 -0.000671  \n",
       "2008-01-01  0.000258  0.008501  0.031809  0.006185  0.004971  \n",
       "2008-02-01 -0.000517  0.006404 -0.011561  0.003752  0.002904  \n",
       "2008-03-01 -0.022745  0.017878 -0.017544  0.004939  0.008668  \n",
       "2008-04-01  0.004761  0.020332  0.025794  0.000037  0.006065  \n",
       "\n",
       "[100 rows x 17 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_data = pd.concat([df_beef , df_chicken,df_eggs, df_bread,df_diesel,df_electric,df_energy,df_flour,df_fuel, df_gas,df_malt, df_medical, df_milk,df_utility,df_sugar, df_shelter, df_cpi], axis=\"columns\", join = \"inner\")\n",
    "\n",
    "group_data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beef</th>\n",
       "      <th>Chicken</th>\n",
       "      <th>Eggs</th>\n",
       "      <th>Bread</th>\n",
       "      <th>Diesel</th>\n",
       "      <th>Electric79_22</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Flour</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Gasoline</th>\n",
       "      <th>Malt</th>\n",
       "      <th>Medical</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Utility</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>Shelter</th>\n",
       "      <th>CPI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-02-01</th>\n",
       "      <td>0.025382</td>\n",
       "      <td>-0.016351</td>\n",
       "      <td>-0.004980</td>\n",
       "      <td>0.016850</td>\n",
       "      <td>0.019370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012323</td>\n",
       "      <td>0.022099</td>\n",
       "      <td>0.043033</td>\n",
       "      <td>0.011190</td>\n",
       "      <td>0.062998</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>-0.020701</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>0.003698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-01</th>\n",
       "      <td>0.040225</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>0.031532</td>\n",
       "      <td>-0.020893</td>\n",
       "      <td>0.011654</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.034338</td>\n",
       "      <td>-0.007207</td>\n",
       "      <td>-0.029470</td>\n",
       "      <td>0.050550</td>\n",
       "      <td>-0.064516</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.030329</td>\n",
       "      <td>0.014671</td>\n",
       "      <td>-0.017886</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.006440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-01</th>\n",
       "      <td>0.029746</td>\n",
       "      <td>-0.009067</td>\n",
       "      <td>0.028142</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>-0.006011</td>\n",
       "      <td>-0.029630</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>-0.007260</td>\n",
       "      <td>-0.030870</td>\n",
       "      <td>0.035705</td>\n",
       "      <td>0.067362</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>-0.019606</td>\n",
       "      <td>-0.008278</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.003297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-01</th>\n",
       "      <td>0.012605</td>\n",
       "      <td>0.016993</td>\n",
       "      <td>-0.058046</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>-0.009322</td>\n",
       "      <td>0.038168</td>\n",
       "      <td>0.013481</td>\n",
       "      <td>-0.027422</td>\n",
       "      <td>-0.003916</td>\n",
       "      <td>0.006656</td>\n",
       "      <td>-0.069121</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.013019</td>\n",
       "      <td>0.018151</td>\n",
       "      <td>0.013356</td>\n",
       "      <td>0.003224</td>\n",
       "      <td>0.003493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-01</th>\n",
       "      <td>0.006224</td>\n",
       "      <td>-0.034062</td>\n",
       "      <td>-0.024048</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>-0.003306</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>0.016759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009436</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.083132</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>-0.029183</td>\n",
       "      <td>0.028472</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.001862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>-0.010860</td>\n",
       "      <td>0.009963</td>\n",
       "      <td>0.078859</td>\n",
       "      <td>0.015013</td>\n",
       "      <td>0.003824</td>\n",
       "      <td>0.035211</td>\n",
       "      <td>0.018268</td>\n",
       "      <td>0.092784</td>\n",
       "      <td>0.096718</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.008940</td>\n",
       "      <td>0.009266</td>\n",
       "      <td>0.011755</td>\n",
       "      <td>0.029073</td>\n",
       "      <td>0.021708</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.008415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01</th>\n",
       "      <td>0.016689</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.039399</td>\n",
       "      <td>0.014791</td>\n",
       "      <td>0.060952</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.025413</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.074682</td>\n",
       "      <td>0.053520</td>\n",
       "      <td>0.024051</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>0.023237</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.016997</td>\n",
       "      <td>0.005846</td>\n",
       "      <td>0.009134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-01</th>\n",
       "      <td>0.027430</td>\n",
       "      <td>0.056373</td>\n",
       "      <td>0.020449</td>\n",
       "      <td>0.018378</td>\n",
       "      <td>0.235701</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.105373</td>\n",
       "      <td>0.046729</td>\n",
       "      <td>0.214391</td>\n",
       "      <td>0.197870</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>0.010839</td>\n",
       "      <td>0.014263</td>\n",
       "      <td>0.029248</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>0.013351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01</th>\n",
       "      <td>0.033424</td>\n",
       "      <td>0.040603</td>\n",
       "      <td>0.231672</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>0.062474</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.043628</td>\n",
       "      <td>-0.010087</td>\n",
       "      <td>-0.004305</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.024253</td>\n",
       "      <td>0.010226</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>0.005583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-01</th>\n",
       "      <td>-0.024817</td>\n",
       "      <td>0.016722</td>\n",
       "      <td>0.136111</td>\n",
       "      <td>-0.003722</td>\n",
       "      <td>0.077750</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>0.056968</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.161384</td>\n",
       "      <td>0.078445</td>\n",
       "      <td>0.006794</td>\n",
       "      <td>0.003523</td>\n",
       "      <td>0.047856</td>\n",
       "      <td>0.027094</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.011024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Beef   Chicken      Eggs     Bread    Diesel  Electric79_22  \\\n",
       "Year                                                                          \n",
       "2014-02-01  0.025382 -0.016351 -0.004980  0.016850  0.019370       0.000000   \n",
       "2014-03-01  0.040225  0.026596  0.031532 -0.020893  0.011654       0.007463   \n",
       "2014-04-01  0.029746 -0.009067  0.028142  0.021339 -0.006011      -0.029630   \n",
       "2014-05-01  0.012605  0.016993 -0.058046  0.009366 -0.009322       0.038168   \n",
       "2014-06-01  0.006224 -0.034062 -0.024048 -0.000714 -0.003306       0.051471   \n",
       "...              ...       ...       ...       ...       ...            ...   \n",
       "2022-01-01 -0.010860  0.009963  0.078859  0.015013  0.003824       0.035211   \n",
       "2022-02-01  0.016689  0.006165  0.039399  0.014791  0.060952       0.006803   \n",
       "2022-03-01  0.027430  0.056373  0.020449  0.018378  0.235701       0.013514   \n",
       "2022-04-01  0.033424  0.040603  0.231672  0.003111  0.062474       0.006667   \n",
       "2022-05-01 -0.024817  0.016722  0.136111 -0.003722  0.077750       0.019868   \n",
       "\n",
       "              Energy     Flour      Fuel  Gasoline      Malt   Medical  \\\n",
       "Year                                                                     \n",
       "2014-02-01  0.012323  0.022099  0.043033  0.011190  0.062998  0.007514   \n",
       "2014-03-01  0.034338 -0.007207 -0.029470  0.050550 -0.064516  0.000990   \n",
       "2014-04-01  0.007494 -0.007260 -0.030870  0.035705  0.067362  0.001574   \n",
       "2014-05-01  0.013481 -0.027422 -0.003916  0.006656 -0.069121  0.001815   \n",
       "2014-06-01  0.016759  0.000000 -0.009436  0.002835  0.083132  0.000671   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-01-01  0.018268  0.092784  0.096718  0.000796  0.008940  0.009266   \n",
       "2022-02-01  0.025413  0.009434  0.074682  0.053520  0.024051  0.003491   \n",
       "2022-03-01  0.105373  0.046729  0.214391  0.197870  0.004944  0.005085   \n",
       "2022-04-01  0.001888  0.015625  0.043628 -0.010087 -0.004305  0.003156   \n",
       "2022-05-01  0.056968  0.002198  0.161384  0.078445  0.006794  0.003523   \n",
       "\n",
       "                Milk   Utility     Sugar   Shelter       CPI  \n",
       "Year                                                          \n",
       "2014-02-01  0.002534  0.011339 -0.020701  0.002489  0.003698  \n",
       "2014-03-01  0.030329  0.014671 -0.017886  0.003788  0.006440  \n",
       "2014-04-01  0.004906 -0.019606 -0.008278  0.001743  0.003297  \n",
       "2014-05-01  0.013019  0.018151  0.013356  0.003224  0.003493  \n",
       "2014-06-01 -0.029183  0.028472  0.004942  0.002031  0.001862  \n",
       "...              ...       ...       ...       ...       ...  \n",
       "2022-01-01  0.011755  0.029073  0.021708  0.003994  0.008415  \n",
       "2022-02-01  0.023237  0.000597  0.016997  0.005846  0.009134  \n",
       "2022-03-01  0.010839  0.014263  0.029248  0.005836  0.013351  \n",
       "2022-04-01  0.024253  0.010226  0.001353  0.005109  0.005583  \n",
       "2022-05-01  0.047856  0.027094  0.006757  0.006289  0.011024  \n",
       "\n",
       "[100 rows x 17 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_data.tail(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is used for model prototyping, but it is good practice to comment this out and run multiple experiments to evaluate your model.\n",
    "#from numpy.random import seed\n",
    "\n",
    "#seed(1)\n",
    "#from tensorflow import random\n",
    "\n",
    "#random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "In this activity, we will use closing prices from different stocks to make predictions of future closing prices based on the temporal data of each stock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Features `X` and Target `y` Data\n",
    "\n",
    "The first step towards preparing the data is to create the input features vectors `X` and the target vector `y`. We will use the `window_data()` function to create these vectors.\n",
    "\n",
    "This function chunks the data up with a rolling window of _X<sub>t</sub> - window_ to predict _X<sub>t</sub>_.\n",
    "\n",
    "The function returns two `numpy` arrays:\n",
    "\n",
    "* `X`: The input features vectors.\n",
    "\n",
    "* `y`: The target vector.\n",
    "\n",
    "The function has the following parameters:\n",
    "\n",
    "* `df`: The original DataFrame with the time series data.\n",
    "\n",
    "* `window`: The window size in days of previous closing prices that will be used for the prediction.\n",
    "\n",
    "* `feature_col_number`: The column number from the original DataFrame where the features are located.\n",
    "\n",
    "* `target_col_number`: The column number from the original DataFrame where the target is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    \"\"\"\n",
    "    This function accepts the column number for the features (X) and the target (y).\n",
    "    It chunks the data up with a rolling window of Xt - window to predict Xt.\n",
    "    It returns two numpy arrays of X and y.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = group_data.iloc[:,0:14].values\n",
    "y = group_data.iloc[:,15:15].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remainder for testing\n",
    "split = int(0.7 * len(X))\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the forthcoming activities, we will predict closing prices using a `5` days windows of previous _T-Bonds_ closing prices, so that, we will create the `X` and `y` vectors by calling the `window_data` function and defining a window size of `5` and setting the features and target column numbers to `2` (this is the column with the _T-Bonds_ closing prices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X sample values:\n",
      "[[-0.02945026  0.00569801  0.05978261  0.00889878  0.02579219 -0.01176471\n",
      "          nan  0.07116105  0.09283088  0.00358744  0.05841924         nan\n",
      "  -0.03130435         nan]\n",
      " [ 0.02225219 -0.01227573 -0.01333333  0.01874311  0.12356322  0.01190476\n",
      "   0.03493014 -0.06643357  0.35744323  0.04825737 -0.0465368   0.00597015\n",
      "  -0.00287253  0.02093719]\n",
      " [ 0.01055409  0.01720841 -0.03222453  0.          0.01470588  0.\n",
      "   0.05014465  0.06741573 -0.15799257  0.11594203  0.0692395   0.00395648\n",
      "  -0.01044292 -0.00585938]\n",
      " [ 0.03394256  0.00469925  0.00859291  0.00324675 -0.0384373   0.\n",
      "  -0.01010101 -0.00701754 -0.05371597 -0.02291826 -0.05732484  0.00197044\n",
      "   0.00909753  0.        ]\n",
      " [-0.00883838 -0.01590271 -0.09265176 -0.01294498 -0.00917431  0.\n",
      "   0.00185529  0.06713781 -0.01788491 -0.00234558  0.05292793  0.00294985\n",
      "   0.00324558  0.00884086]] \n",
      "\n",
      "y sample values:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Creating the features (X) and target (y) data using the window_data() function.\n",
    "window_size = 30\n",
    "\n",
    "#feature_column = range(15)\n",
    "feature_column = 16\n",
    "target_column = 16\n",
    "#X, y = window_data(group_data, window_size, feature_column, target_column)\n",
    "print (f\"X sample values:\\n{X[:5]} \\n\")\n",
    "print (f\"y sample values:\\n{y[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data Between Training and Testing Sets\n",
    "\n",
    "To avoid the dataset being randomized, we will manually split the data using array slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample values:\n",
      "[[[-0.02945026]\n",
      "  [ 0.00569801]\n",
      "  [ 0.05978261]\n",
      "  [ 0.00889878]\n",
      "  [ 0.02579219]\n",
      "  [-0.01176471]\n",
      "  [        nan]\n",
      "  [ 0.07116105]\n",
      "  [ 0.09283088]\n",
      "  [ 0.00358744]\n",
      "  [ 0.05841924]\n",
      "  [        nan]\n",
      "  [-0.03130435]\n",
      "  [        nan]]\n",
      "\n",
      " [[ 0.02225219]\n",
      "  [-0.01227573]\n",
      "  [-0.01333333]\n",
      "  [ 0.01874311]\n",
      "  [ 0.12356322]\n",
      "  [ 0.01190476]\n",
      "  [ 0.03493014]\n",
      "  [-0.06643357]\n",
      "  [ 0.35744323]\n",
      "  [ 0.04825737]\n",
      "  [-0.0465368 ]\n",
      "  [ 0.00597015]\n",
      "  [-0.00287253]\n",
      "  [ 0.02093719]]\n",
      "\n",
      " [[ 0.01055409]\n",
      "  [ 0.01720841]\n",
      "  [-0.03222453]\n",
      "  [ 0.        ]\n",
      "  [ 0.01470588]\n",
      "  [ 0.        ]\n",
      "  [ 0.05014465]\n",
      "  [ 0.06741573]\n",
      "  [-0.15799257]\n",
      "  [ 0.11594203]\n",
      "  [ 0.0692395 ]\n",
      "  [ 0.00395648]\n",
      "  [-0.01044292]\n",
      "  [-0.00585938]]\n",
      "\n",
      " [[ 0.03394256]\n",
      "  [ 0.00469925]\n",
      "  [ 0.00859291]\n",
      "  [ 0.00324675]\n",
      "  [-0.0384373 ]\n",
      "  [ 0.        ]\n",
      "  [-0.01010101]\n",
      "  [-0.00701754]\n",
      "  [-0.05371597]\n",
      "  [-0.02291826]\n",
      "  [-0.05732484]\n",
      "  [ 0.00197044]\n",
      "  [ 0.00909753]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[-0.00883838]\n",
      "  [-0.01590271]\n",
      "  [-0.09265176]\n",
      "  [-0.01294498]\n",
      "  [-0.00917431]\n",
      "  [ 0.        ]\n",
      "  [ 0.00185529]\n",
      "  [ 0.06713781]\n",
      "  [-0.01788491]\n",
      "  [-0.00234558]\n",
      "  [ 0.05292793]\n",
      "  [ 0.00294985]\n",
      "  [ 0.00324558]\n",
      "  [ 0.00884086]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[-0.0079346 ]\n",
      "  [-0.00910364]\n",
      "  [ 0.00781515]\n",
      "  [ 0.0084507 ]\n",
      "  [-0.04680535]\n",
      "  [-0.00704225]\n",
      "  [-0.05673453]\n",
      "  [-0.01335878]\n",
      "  [-0.02503078]\n",
      "  [-0.10096611]\n",
      "  [ 0.00306513]\n",
      "  [ 0.00191217]\n",
      "  [ 0.00088522]\n",
      "  [-0.00588335]]\n",
      "\n",
      " [[-0.01042172]\n",
      "  [ 0.01060071]\n",
      "  [-0.0532704 ]\n",
      "  [-0.00977654]\n",
      "  [-0.01325019]\n",
      "  [-0.03546099]\n",
      "  [-0.03555405]\n",
      "  [-0.01160542]\n",
      "  [-0.01094276]\n",
      "  [-0.03938448]\n",
      "  [ 0.0236822 ]\n",
      "  [ 0.00694007]\n",
      "  [-0.01591981]\n",
      "  [-0.02520787]]\n",
      "\n",
      " [[ 0.00734754]\n",
      "  [ 0.03776224]\n",
      "  [-0.05128205]\n",
      "  [-0.00634697]\n",
      "  [-0.01540284]\n",
      "  [-0.01470588]\n",
      "  [-0.02774547]\n",
      "  [-0.02935421]\n",
      "  [-0.02042553]\n",
      "  [-0.04207417]\n",
      "  [ 0.00373134]\n",
      "  [ 0.00288899]\n",
      "  [-0.01168364]\n",
      "  [-0.00929316]]\n",
      "\n",
      " [[-0.01288597]\n",
      "  [-0.03167116]\n",
      "  [ 0.03265766]\n",
      "  [ 0.01348474]\n",
      "  [-0.04612916]\n",
      "  [-0.00746269]\n",
      "  [-0.03367003]\n",
      "  [ 0.01008065]\n",
      "  [-0.08166811]\n",
      "  [-0.0587569 ]\n",
      "  [ 0.00148699]\n",
      "  [-0.00064142]\n",
      "  [ 0.00333434]\n",
      "  [-0.00587939]]\n",
      "\n",
      " [[-0.02019704]\n",
      "  [-0.00556715]\n",
      "  [-0.15376227]\n",
      "  [-0.00210084]\n",
      "  [-0.07779647]\n",
      "  [ 0.0075188 ]\n",
      "  [-0.02000865]\n",
      "  [ 0.04191617]\n",
      "  [-0.06811731]\n",
      "  [-0.04413469]\n",
      "  [ 0.00668151]\n",
      "  [ 0.0072894 ]\n",
      "  [ 0.00090634]\n",
      "  [ 0.00353995]]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the features for the model\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print (f\"X_train sample values:\\n{X_train[:5]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Data with `MinMaxScaler`\n",
    "\n",
    "Once the training and test datasets are created, we need to scale the data before training the LSTM model. We will use the `MinMaxScaler` from `sklearn` to scale all values between `0` and `1`.\n",
    "\n",
    "Note that we scale both features and target sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the MinMaxScaler object with the training feature data X_train\n",
    "#scaler.fit(X_train)\n",
    "\n",
    "# Scale the features training and testing sets\n",
    "#X_train = scaler.transform(X_train)\n",
    "#X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit the MinMaxScaler object with the training target data y_train\n",
    "#scaler.fit(y_train)\n",
    "\n",
    "# Scale the target training and testing sets\n",
    "#y_train = scaler.transform(y_train)\n",
    "#y_test = scaler.transform(y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "scaler = StandardScaler().fit(X_train) \n",
    "X_train_scaled = scaler.transform(X_train) \n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape Features Data for the LSTM Model\n",
    "\n",
    "The LSTM API from Keras needs to receive the features data as a _vertical vector_, so that we need to reshape the `X` data in the form `reshape((X_train.shape[0], X_train.shape[1], 1))`.\n",
    "\n",
    "Both sets, training, and testing are reshaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the features for the model\n",
    "#X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "#X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "#print (f\"X_train sample values:\\n{X_train[:5]} \\n\")\n",
    "#print (f\"X_test sample values:\\n{X_test[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Build and Train the LSTM RNN\n",
    "\n",
    "In this section, we will design a custom LSTM RNN in Keras and fit (train) it using the training data we defined.\n",
    "\n",
    "We will need to:\n",
    "\n",
    "1. Define the model architecture in Keras.\n",
    "\n",
    "2. Compile the model.\n",
    "\n",
    "3. Fit the model to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Keras Modules\n",
    "\n",
    "The LSTM RNN model in Keras uses the `Sequential` model and the `LSTM` layer as we did before. However, there is a new type of layer called `Dropout`.\n",
    "\n",
    "* `Dropout`: Dropout is a regularization technique for reducing overfitting in neural networks. This type of layer applies the dropout technique to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required Keras modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the LSTM RNN Model Structure\n",
    "\n",
    "To create an LSTM RNN model, we will add `LSTM` layers. The `return_sequences` parameter needs to set to `True` every time we add a new `LSTM` layer, excluding the final layer. The `input_shape` is the number of time steps and the number of indicators\n",
    "\n",
    "After each `LSTM` layer, we add a `Dropout` layer to prevent overfitting. The parameter passed to the `Dropout` layer is the fraction of nodes that will be drop on each epoch, for this demo, we will use a dropout value of `0.2`, it means that on each epoch we will randomly drop `20%` of the units.\n",
    "\n",
    "The number of units in each `LSTM` layers, is equal to the size of the time window, in this demo, we are taking five previous `T-Bons` closing price to predict the next closing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model.\n",
    "model = Sequential()\n",
    "\n",
    "number_units = 16\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Output layer\n",
    "model.add(Dense(14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the LSTM RNN Model\n",
    "\n",
    "We will compile the model, using the `adam` optimizer, as loss function, we will use `mean_square_error` since the value we want to predict is continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, 14, 16)            1152      \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 14, 16)            0         \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 14, 16)            2112      \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 14, 16)            0         \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 16)                2112      \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 14)                238       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,614\n",
      "Trainable params: 5,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "Once the model is defined, we train (fit) the model using `10` epochs. Since we are working with time-series data, it's important to set `shuffle=False` since it's necessary to keep the sequential order of the data.\n",
    "\n",
    "We can experiment with the `batch_size` parameter; however, smaller batch size is recommended; in this demo, we will use a `batch_size=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\engine\\training.py\", line 949, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\losses.py\", line 1327, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 14 and 0 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential_5/dense_5/BiasAdd, IteratorGetNext:1)' with input shapes: [?,14], [?,0].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_57616/3737351642.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\engine\\training.py\", line 949, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\scott\\anaconda3\\envs\\pyvizenv\\envs\\pyvizenv2\\lib\\site-packages\\keras\\losses.py\", line 1327, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 14 and 0 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential_5/dense_5/BiasAdd, IteratorGetNext:1)' with input shapes: [?,14], [?,0].\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=4, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Performance\n",
    "\n",
    "In this section, we will evaluate the model using the test data. \n",
    "\n",
    "We will need to:\n",
    "\n",
    "1. Evaluate the model using the `X_test` and `y_test` data.\n",
    "\n",
    "2. Use the `X_test` data to make predictions.\n",
    "\n",
    "3. Create a DataFrame of real (`y_test`) vs predicted values.\n",
    "\n",
    "4. Plot the Real vs predicted values as a line chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model\n",
    "\n",
    "It's time to evaluate our model to assess its performance. We will use the `evaluate` method using the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions\n",
    "\n",
    "We will make some closing price predictions using our brand new LSTM RNN model and our testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we scaled the original values using the `MinMaxScaler`, we need to recover the original prices to better understand the predictions.\n",
    "\n",
    "We will use the `inverse_transform()` method of the scaler to decode the scaled values to their original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predicted)\n",
    "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Predicted Vs. Real Prices\n",
    "\n",
    "To plot the predicted vs. the real values, we will create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "stocks = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "    }, index = group_data.index[-len(real_prices): ])\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the real vs predicted prices as a line chart\n",
    "stocks.plot()"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "vscode": {
   "interpreter": {
    "hash": "f24fb736bc58afe020740221a10e8176565a9d617573dc102cc641ee173f1291"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
